AI techniques have allowed computers to surpass human performance in adversarial
games of perfect information, but minimax with alphabeta pruning and Monte Carlo
tree search have been unable to tame the complexity of the game of Go. In
Mastering the game of Go with deep neural networks and tree search, the authors
present a new technique that combines Monte Carlo simulation with value networks
to evaluate positions and policy networks to select moves, resulting in an
engine capable of defeating professional human Go players.

The neural networks are trained with several stages of machine learning. First,
supervised learning (SL) is used to train a policy network with games from human
experts. In a novel approach, reinforcement learning (RL) is then used to train
another policy network that improves the SL network, and finally, the RL policy
network is used to train a value network by predicting the winner of games
played by the RL policy network against itself.

The RL training phase had a significant boost on AlphaGo's performance level.
The RL network dominated the SL policy network in games played against each
other, winning more than 80% of matches. Pitted against Pachi, an open-source Go
engine, the RL network won more than 85% of games without doing any search.

The last stage of training focused on position evaluation. The evaluation and
policity networks have similar architectures, but the evaluation networks
outputs a single prediction value reprenting the best move, whereas the policy
network outputs a probability distribution representing the likelihood of each
legal move from a given board state.

In the end, the policy and value networks are combined with Monte Carlo tree
search (MCTS). To combine MCTS with deep neural networks, which are more
computationaly intensive than traditonal search algorithms, AlphaGo uses an
asyncrhonous model, searching by running simulations on the CPUs, while policy
and value networks are computed in parallel on GPUs.

Thus, the most immediate consequence of this innovative technique of combining
deep neural networks with MCTS is the utter dominion by computers of games
of perfect information; however, as with other discoveries of AI techniques,
this may be a stepping stone for breakthroughs in other areas of AI.
